{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retreive all URL of the top x varieties\n",
    "\n",
    "def get_top_cepages(x):\n",
    "    \"\"\"\n",
    "    @param x : number of varieties required (8) in our case\n",
    "    pre : x, the number of varieties\n",
    "    post : the list of urls of the 8 varieties we wanted on the winedexer website\n",
    "    \"\"\"\n",
    "    to_retreive = (\"cabernet-sauvignon\",\"chardonnay\",\"pinot-noir\",\"merlot\",\"riesling\",\"malbec\",\"sangiovese\",\"zinfandel\")\n",
    "    # Basic url\n",
    "    url = \"https://www.winedexer.com/top-vin-cepage\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    grape_links = soup.find_all(\"link\")\n",
    "    top = []\n",
    "    for link in grape_links:\n",
    "        href = link.get(\"href\")\n",
    "        if href and href.startswith(\"/top-vin-cepage/\") and href.endswith(to_retreive):\n",
    "            cepage_url = \"https://www.winedexer.com\" + href\n",
    "            top.append(cepage_url)\n",
    "            if len(top) == x:\n",
    "                break\n",
    "    return top\n",
    "\n",
    "#Access the URL of each wine \n",
    "\n",
    "def extract_cepages(url):\n",
    "    \"\"\"\n",
    "    @param url : url extension of a wine (url without \"https://www.winedexer.com\")\n",
    "    pre : url extension of a wine\n",
    "    post : return True is the wine is composed of only one grape variety, False otherwise\n",
    "    \"\"\"\n",
    "    response = requests.get(\"https://www.winedexer.com\"+url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    grape_links = soup.find_all(\"a\")\n",
    "    cepage_list = []\n",
    "    for a in grape_links:\n",
    "        style = a.get(\"href\")\n",
    "        if style and style.startswith(\"/top-vin-cepage-pays/\"):\n",
    "            cepage_list.append(a.get_text())\n",
    "    if len(cepage_list) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def get_url_wines(x,list_of_quantities):\n",
    "    \"\"\"\n",
    "    @param x : number of varieties required (8) in our case\n",
    "    @param list_of_quantities: a list specifying the number of observations wished for each class. The length \n",
    "    of this list should then be equal to the parameter x. The quantities of this list will follow the same order than the\n",
    "    output of get_top_cepages\n",
    "    \n",
    "    pre : x & list_of_quantities\n",
    "    post : a list of all urls needed\n",
    "    \n",
    "    \"\"\"\n",
    "    # Get the list of urls for the different varieties\n",
    "    list_of_url = get_top_cepages(x)\n",
    "    list_of_wine_link = []\n",
    "    counter = 0\n",
    "    \n",
    "    #For each variety\n",
    "    for url in list_of_url: \n",
    "        nbr = 0\n",
    "        blend = 0\n",
    "        counter2 = 1\n",
    "        first = True\n",
    "        # While I have not reached the number of observations desired for this specific variety\n",
    "        while nbr < list_of_quantities[counter]: \n",
    "\n",
    "            # I check if this is the first iteration : if yes, I keep the url of the variety as it is, If not, I access the next page\n",
    "            if first:\n",
    "                response = requests.get(url)\n",
    "            else:\n",
    "                response = requests.get(url + \"?page=\" + str(counter2))\n",
    "            \n",
    "            # I parse the html page of the variety to retreive all urls of the wines and I check if there is only one variety\n",
    "            # I back up the urls in a json file\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            allas = soup.find_all(\"a\")\n",
    "            for a in allas:\n",
    "                href = a.get(\"href\")\n",
    "                if href and href.startswith(\"/vin\") and len(list_of_wine_link) < sum(list_of_quantities) and nbr <list_of_quantities[counter]:\n",
    "                    if (extract_cepages(href)== True):\n",
    "                        list_of_wine_link.append(href)\n",
    "                        nbr+=1\n",
    "                        print(nbr)\n",
    "                        with open(f\"output_urls.json\", 'w', encoding='utf-8') as f:\n",
    "                            json.dump(list_of_wine_link, f, ensure_ascii=False, indent=4, default=str)\n",
    "            counter2+=1 \n",
    "            first = False\n",
    "            # There is a maximum of 10 pages on the website\n",
    "            if counter2 == 11:\n",
    "                break\n",
    "        # If after the 10 pages, I still dont have the required number of observations, I retreive wine urls by country this time\n",
    "        if nbr < list_of_quantities[counter]:\n",
    "            # While I have not reached the number of observations desired for this specific variety\n",
    "            while nbr < list_of_quantities[counter]:\n",
    "                first = True\n",
    "                list_of_countries = [\"albanie\",\"argentine\",\"armenie\",\"australie\",\"autriche\",\"azerbaijan\",\"belgique\",\"bolivie\",\n",
    "                                     \"bresil\",\"bulgarie\",\"canada\",\"chili\",\"chine\",\"croatie\",\"chypre\",\"republique-tcheque\",\n",
    "                                     \"danemark\",\"equateur\",\"france\",\"georgie\",\"allemagne\",\"grece\",\"hongrie\",\"inde\",\"israel\",\n",
    "                                     \"italie\",\"japon\",\"kazakhstan\",\"kosovo\",\"liban\",\"luxembourg\",\"macedoine\",\"malte\",\"mexique\",\n",
    "                                     \"moldavie\",\"montenegro\",\"maroc\",\"pays-bas\",\"nouvelle-zelande\",\"palestine\",\"perou\",\"pologne\",\n",
    "                                     \"portugal\",\"roumanie\",\"russie\",\"serbie\",\"slovaquie\",\"slovenie\",\"afrique-du-sud\",\"espagne\",\n",
    "                                     \"suede\",\"suisse\",\"tunisie\",\"turquie\",\"ukraine\",\"royaume-uni\",\"etats-unis\",\"uruguay\"]\n",
    "                # For each country\n",
    "                for i in list_of_countries:\n",
    "                    counter2 = 1\n",
    "                    try:\n",
    "                        # I check if this is the first iteration : if yes, I keep the url of the variety as it is, If not, I access the next page\n",
    "\n",
    "                        if first:\n",
    "                            response = requests.get(url+i)\n",
    "                        else:\n",
    "                            response = requests.get(url + i +\"?page=\" + str(counter2))\n",
    "                        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "                        allas = soup.find_all(\"a\")\n",
    "                        \n",
    "                        #I parse the html page ad retreive all urls of wines with only one variety\n",
    "                        # I back up the urls in a json file\n",
    "                        for a in allas:\n",
    "                            href = a.get(\"href\")\n",
    "                            new_page = a.get(\"class\")\n",
    "                            if href and href.startswith(\"/vin\") and len(list_of_wine_link) < sum(list_of_quantities) and nbr <list_of_quantities[counter]:\n",
    "                                if (extract_cepages(href)== True):\n",
    "                                    list_of_wine_link.append(href)\n",
    "                                    nbr+=1\n",
    "                                    print(nbr)\n",
    "                                    with open(f\"output_urls.json\", 'w', encoding='utf-8') as f:\n",
    "                                        json.dump(list_of_wine_link, f, ensure_ascii=False, indent=4, default=str)\n",
    "                                    if nbr == list_of_quantities[counter]:\n",
    "                                        break\n",
    "                            # I check if there is a second page, if not, we change of country\n",
    "                            if new_page and new_page.startswith(\"page-link disabled\") and new_page.get_text() == \"Vins suivants\":\n",
    "                                new_page = False\n",
    "                        counter+=1\n",
    "                        first = False\n",
    "                        if new_page == False:\n",
    "                            break\n",
    "                    except:\n",
    "                        continue\n",
    "            \n",
    "        \n",
    "        counter+=1\n",
    "    return list_of_wine_link\n",
    "\n",
    "\n",
    "\n",
    "#result = get_url_wines(8,[8182,8696,8802,3131,3384,1910,1860,2403])\n",
    "result = get_url_wines(8,[2000,500,500,500,500,500,500,500])\n",
    "df = pd.DataFrame(result, columns = ['URLS'])\n",
    "df.to_csv(\"urls.csv\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
